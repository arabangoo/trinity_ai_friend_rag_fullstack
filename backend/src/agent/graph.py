"""Perplexity + Gemini Research Agent (MemorySaver)"""
import os
from typing import Literal
from langgraph.graph import StateGraph, START, END
# MemorySaver ì œê±° - LangGraph APIê°€ persistence ìë™ ì²˜ë¦¬
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage
from agent.state import ResearchState
from tools.perplexity import perplexity_search

# Gemini ì´ˆê¸°í™”
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY not found in environment")

gemini = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash-exp",
    temperature=0.3,
    api_key=GEMINI_API_KEY,
    max_output_tokens=8192  # ê¸°ì¡´ 4096ì—ì„œ 8192ë¡œ 2ë°° ì¦ê°€
)

def extract_query(state: ResearchState) -> ResearchState:
    """ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ì¿¼ë¦¬ ì¶”ì¶œ"""
    messages = state.get("messages", [])
    if messages:
        last_message = messages[-1]
        if hasattr(last_message, 'content'):
            state["query"] = last_message.content
    state.setdefault("iteration", 0)
    state.setdefault("search_results", [])
    state.setdefault("citations", [])
    state.setdefault("related_questions", [])
    state.setdefault("image", None)  # ì´ë¯¸ì§€ í•„ë“œ ì´ˆê¸°í™”
    return state


async def search_perplexity(state: ResearchState) -> ResearchState:
    """Perplexityë¡œ ì›¹ ê²€ìƒ‰ (ì´ë¯¸ì§€ ì„¤ëª… í¬í•¨)"""
    query = state["query"]
    image = state.get("image")
    
    # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ Geminië¡œ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±
    if image:
        print(f"\nğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
        image_prompt = "ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì£¼ìš” ê°ì²´, ìƒ‰ìƒ, ë¶„ìœ„ê¸° ë“±ì„ í¬í•¨í•´ì£¼ì„¸ìš”."
        
        # Geminië¡œ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±
        image_content = [
            {"type": "text", "text": image_prompt},
            {
                "type": "image_url",
                "image_url": {"url": f"data:image/webp;base64,{image}"}
            }
        ]
        
        try:
            img_response = await gemini.ainvoke([HumanMessage(content=image_content)])
            image_description = img_response.content
            print(f"âœ… ì´ë¯¸ì§€ ì„¤ëª…: {image_description[:100]}...")
            
            # ì›ë˜ ì¿¼ë¦¬ì— ì´ë¯¸ì§€ ì„¤ëª… ì¶”ê°€
            query = f"{query}\n\n[ì´ë¯¸ì§€ ì„¤ëª…: {image_description}]"
            state["query"] = query  # ì—…ë°ì´íŠ¸ëœ ì¿¼ë¦¬ ì €ì¥
            
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
    
    print(f"\nğŸ” [ê²€ìƒ‰ {state['iteration'] + 1}] Perplexity: {query[:100]}...")
    result = await perplexity_search.ainvoke({"query": query, "search_recency": "month"})
    if "error" in result:
        print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {result['error']}")
        result = {"content": "", "citations": [], "related_questions": []}
    state["search_results"].append(result)
    state["citations"].extend(result.get("citations", []))
    state["related_questions"] = result.get("related_questions", [])
    state["iteration"] += 1
    print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(result.get('citations', []))}ê°œ ì¶œì²˜")
    return state

async def analyze_with_gemini(state: ResearchState) -> ResearchState:
    """Geminië¡œ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„"""
    query = state["query"]
    all_content = "\n\n".join([r.get('content', '') for r in state["search_results"] if r.get('content')])
    if not all_content:
        state["analysis"] = "No results"
        state["needs_more_research"] = False
        return state
    print(f"\nğŸ§  Gemini ë¶„ì„ ì¤‘...")
    prompt = f"ì§ˆë¬¸: {query}\n\nê²€ìƒ‰ê²°ê³¼:\n{all_content}\n\nì •ë³´ê°€ ì¶©ë¶„í•˜ë©´ SUFFICIENT: YES, ë¶€ì¡±í•˜ë©´ SUFFICIENT: NO"
    try:
        response = await gemini.ainvoke([HumanMessage(content=prompt)])
        state["analysis"] = response.content
        state["needs_more_research"] = "SUFFICIENT: NO" in response.content.upper() and state["iteration"] < 3
        print(f"âœ… ë¶„ì„ ì™„ë£Œ | ì¶”ê°€ ê²€ìƒ‰: {state['needs_more_research']}")
    except Exception as e:
        print(f"âŒ Gemini ì˜¤ë¥˜: {str(e)}")
        state["analysis"] = f"Error: {str(e)}"
        state["needs_more_research"] = False
    return state


async def generate_final_answer(state: ResearchState) -> ResearchState:
    """ìµœì¢… ë‹µë³€ ìƒì„± (ë©€í‹°ëª¨ë‹¬ ì§€ì›)"""
    query = state["query"]
    image = state.get("image")
    all_content = "\n\n".join([r.get('content', '') for r in state["search_results"] if r.get('content')])
    
    print(f"\nğŸ“ ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘...")
    
    if not all_content:
        answer = "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    else:
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        text_prompt = f"""ì§ˆë¬¸: {query}

ê²€ìƒ‰ ì •ë³´:
{all_content}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª…í™•í•˜ê³  ì „ë¬¸ì ì´ë©° ìƒì„¸í•œ í•œêµ­ì–´ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
ë‹µë³€ì€ ìµœì†Œ 2-3ê°œ ë‹¨ë½ìœ¼ë¡œ êµ¬ì„±í•˜ê³ , êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ì„¤ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”."""

        # ë©€í‹°ëª¨ë‹¬ ì»¨í…ì¸  êµ¬ì„±
        content = [{"type": "text", "text": text_prompt}]
        
        if image:
            content.append({
                "type": "image_url",
                "image_url": {"url": f"data:image/webp;base64,{image}"}
            })
            print(f"ğŸ“¸ ì´ë¯¸ì§€ í¬í•¨í•˜ì—¬ ë‹µë³€ ìƒì„±")
        
        try:
            response = await gemini.ainvoke([HumanMessage(content=content)])
            answer = response.content
            
        except Exception as e:
            print(f"âŒ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            answer = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    # ì¶œì²˜ ë° ê´€ë ¨ ì§ˆë¬¸ ì¶”ê°€
    citations = list(set(state["citations"]))
    if citations:
        answer += "\n\n---\n**ğŸ“š ì°¸ê³  ì¶œì²˜:**\n"
        for i, cite in enumerate(citations[:10], 1):
            answer += f"\n[{i}] {cite}"
    if state.get("related_questions"):
        answer += "\n\n---\n**ğŸ”— ê´€ë ¨ ì§ˆë¬¸:**\n"
        for q in state["related_questions"][:5]:
            answer += f"\nâ€¢ {q}"
    state["final_answer"] = answer
    state["messages"].append(AIMessage(content=answer))
    print(f"âœ… ìµœì¢… ë‹µë³€ ì™„ë£Œ (ê¸¸ì´: {len(answer)} ë¬¸ì)")
    return state

def should_continue(state: ResearchState) -> Literal["search", "answer"]:
    """ì¶”ê°€ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€"""
    return "search" if state.get("needs_more_research", False) else "answer"

def create_research_graph():
    """ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ìƒì„± (LangGraph API í˜¸í™˜)"""
    workflow = StateGraph(ResearchState)
    workflow.add_node("extract", extract_query)
    workflow.add_node("search", search_perplexity)
    workflow.add_node("analyze", analyze_with_gemini)
    workflow.add_node("answer", generate_final_answer)
    workflow.add_edge(START, "extract")
    workflow.add_edge("extract", "search")
    workflow.add_edge("search", "analyze")
    workflow.add_conditional_edges("analyze", should_continue, {"search": "search", "answer": "answer"})
    workflow.add_edge("answer", END)
    print("ğŸ’¾ ëŒ€í™” ì €ì¥: LangGraph API ìë™ ê´€ë¦¬")
    return workflow.compile()  # checkpointer ì œê±° - LangGraph APIê°€ ìë™ ì²˜ë¦¬

research_graph = create_research_graph()
graph = research_graph  # langgraph.json í˜¸í™˜ì„±ì„ ìœ„í•œ alias
