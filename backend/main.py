"""
Multi-AI Chat System with Gemini File Search RAG
FastAPI Backend Server
"""

from fastapi import FastAPI, File, UploadFile, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import os
import tempfile
import time
import asyncio
import json
from datetime import datetime
import re
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

from ai_manager import AIManager
from file_search_manager import FileSearchManager

app = FastAPI(title="Multi-AI RAG Chat System")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# AI Manager ë° File Search Manager ì´ˆê¸°í™”
ai_manager = AIManager()
file_search_manager = FileSearchManager()

# ëŒ€í™” íˆìŠ¤í† ë¦¬ (ë©”ëª¨ë¦¬ ì €ì¥ - í”„ë¡œë•ì…˜ì—ì„œëŠ” DB ì‚¬ìš©)
chat_history: List[Dict[str, Any]] = []

# Request Models
class ChatRequest(BaseModel):
    message: str
    include_context: bool = True

class AIResponse(BaseModel):
    ai_name: str
    response: str
    timestamp: str
    has_context: bool = False

# ==================== ì‹œì‘ ì‹œ ì´ˆê¸°í™” ====================

@app.on_event("startup")
async def startup_event():
    """ì•± ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    print("ğŸš€ Trinity AI Friend ì‹œì‘")
    
    # AI ì—°ê²° í™•ì¸
    available_ais = ai_manager.get_available_ais()
    print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ AI: {', '.join(available_ais)}")

# ==================== í—¬ìŠ¤ ì²´í¬ ====================

@app.get("/health")
async def health_check():
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    return {
        "status": "healthy",
        "available_ais": ai_manager.get_available_ais(),
        "uploaded_files_count": len(file_search_manager.get_uploaded_files()),
        "chat_history_count": len(chat_history)
    }

# ==================== íŒŒì¼ ì—…ë¡œë“œ ====================

@app.post("/api/upload")
async def upload_file(file: UploadFile = File(...)):
    """
    íŒŒì¼ ì—…ë¡œë“œ ë° File Search Storeì— ì¸ë±ì‹±
    """
    try:
        # íŒŒì¼ ê²€ì¦
        allowed_extensions = {'.pdf', '.docx', '.txt', '.json', '.png', '.jpg', '.jpeg'}
        file_ext = os.path.splitext(file.filename)[1].lower()
        
        if file_ext not in allowed_extensions:
            raise HTTPException(400, f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")
        
        # íŒŒì¼ ì½ê¸°
        content = await file.read()
        file_size = len(content)
        
        if file_size > 100 * 1024 * 1024:  # 100MB
            raise HTTPException(400, "íŒŒì¼ í¬ê¸°ëŠ” 100MB ì´í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤")
        
        # ì„ì‹œ íŒŒì¼ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp:
            tmp.write(content)
            tmp_path = tmp.name
        
        # File Search Storeì— ì—…ë¡œë“œ
        print(f"ğŸ“¤ ì—…ë¡œë“œ ì‹œì‘: {file.filename}")
        result = await file_search_manager.upload_file(tmp_path, file.filename)
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.unlink(tmp_path)
        
        # íˆìŠ¤í† ë¦¬ì— ê¸°ë¡
        chat_history.append({
            "type": "system",
            "message": f"ğŸ“ íŒŒì¼ ì—…ë¡œë“œ: {file.filename}",
            "timestamp": datetime.now().isoformat(),
            "file_info": result
        })
        
        return {
            "success": True,
            "message": "íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ",
            "filename": file.filename,
            "file_size": file_size,
            **result
        }
        
    except Exception as e:
        if 'tmp_path' in locals():
            try:
                os.unlink(tmp_path)
            except:
                pass
        raise HTTPException(500, f"ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

# ==================== ì±„íŒ… ====================

def parse_message(message: str) -> tuple[str, List[str]]:
    """
    ë©”ì‹œì§€ì—ì„œ AI ì§€ëª… íŒŒì‹±
    @GPT, @Claude, @Gemini
    
    Returns:
        (ì‹¤ì œ ë©”ì‹œì§€, ì§€ëª…ëœ AI ë¦¬ìŠ¤íŠ¸)
    """
    # AI ì§€ëª… íŒ¨í„´ ì°¾ê¸°
    mentions = re.findall(r'@(GPT|Claude|Gemini)', message, re.IGNORECASE)
    
    # ì§€ëª… ì œê±°í•œ ì‹¤ì œ ë©”ì‹œì§€
    clean_message = re.sub(r'@(GPT|Claude|Gemini)\s*', '', message, flags=re.IGNORECASE).strip()
    
    # ëŒ€ì†Œë¬¸ì ì •ê·œí™”
    mentioned_ais = [ai.upper() if ai.upper() == 'GPT' else ai.capitalize() for ai in mentions]
    
    return clean_message, mentioned_ais

@app.post("/api/chat")
async def chat(request: ChatRequest):
    """
    ì±„íŒ… ìš”ì²­ ì²˜ë¦¬ (ì¼ë°˜ ì‘ë‹µ)
    """
    try:
        # ë©”ì‹œì§€ íŒŒì‹±
        clean_message, mentioned_ais = parse_message(request.message)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        user_message = {
            "type": "user",
            "message": request.message,
            "timestamp": datetime.now().isoformat()
        }
        chat_history.append(user_message)
        
        # File Search ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        file_search_context = None
        if request.include_context:
            file_search_context = await file_search_manager.get_context(clean_message)

        # AI ì‘ë‹µ ìƒì„±
        responses = []

        if mentioned_ais:
            # ì§€ëª…ëœ AIë§Œ ì‘ë‹µ
            for ai_name in mentioned_ais:
                response = await ai_manager.get_response(
                    ai_name,
                    clean_message,
                    context=None,  # ê¸°ì¡´ ë¬¸ìì—´ ì»¨í…ìŠ¤íŠ¸ëŠ” ì‚¬ìš© ì•ˆí•¨
                    history=chat_history,
                    file_search_context=file_search_context  # File Search Store ì»¨í…ìŠ¤íŠ¸
                )
                responses.append({
                    "ai_name": ai_name,
                    "response": response,
                    "timestamp": datetime.now().isoformat(),
                    "has_context": file_search_context is not None
                })
        else:
            # ëœë¤ìœ¼ë¡œ 1~3ê°œ AI ì„ íƒ
            import random
            available_ais = ai_manager.get_available_ais()
            selected_ais = random.sample(available_ais, k=random.randint(1, len(available_ais)))

            for ai_name in selected_ais:
                response = await ai_manager.get_response(
                    ai_name,
                    clean_message,
                    context=None,
                    history=chat_history,
                    file_search_context=file_search_context
                )
                responses.append({
                    "ai_name": ai_name,
                    "response": response,
                    "timestamp": datetime.now().isoformat(),
                    "has_context": file_search_context is not None
                })
        
        # ì‘ë‹µ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        for resp in responses:
            chat_history.append({
                "type": "ai",
                "ai_name": resp["ai_name"],
                "message": resp["response"],
                "timestamp": resp["timestamp"]
            })
        
        return {
            "success": True,
            "user_message": clean_message,
            "mentioned_ais": mentioned_ais,
            "responses": responses
        }
        
    except Exception as e:
        raise HTTPException(500, f"ì±„íŒ… ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

# ==================== ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ====================

@app.post("/api/chat/stream")
async def chat_stream(request: ChatRequest):
    """
    ì±„íŒ… ìš”ì²­ ì²˜ë¦¬ (ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ)
    """
    async def generate():
        try:
            # ë©”ì‹œì§€ íŒŒì‹±
            clean_message, mentioned_ais = parse_message(request.message)
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            chat_history.append({
                "type": "user",
                "message": request.message,
                "timestamp": datetime.now().isoformat()
            })
            
            # File Search ì»¨í…ìŠ¤íŠ¸
            file_search_context = None
            if request.include_context:
                file_search_context = await file_search_manager.get_context(clean_message)

            # AI ì„ íƒ
            if mentioned_ais:
                selected_ais = mentioned_ais
            else:
                import random
                available_ais = ai_manager.get_available_ais()
                selected_ais = random.sample(available_ais, k=random.randint(1, len(available_ais)))

            # ê° AIë³„ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
            for ai_name in selected_ais:
                yield f"data: {json.dumps({'type': 'start', 'ai_name': ai_name})}\n\n"

                full_response = ""
                async for chunk in ai_manager.get_response_stream(
                    ai_name,
                    clean_message,
                    context=None,
                    history=chat_history,
                    file_search_context=file_search_context
                ):
                    full_response += chunk
                    yield f"data: {json.dumps({'type': 'chunk', 'ai_name': ai_name, 'text': chunk})}\n\n"

                yield f"data: {json.dumps({'type': 'done', 'ai_name': ai_name})}\n\n"
                
                # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                chat_history.append({
                    "type": "ai",
                    "ai_name": ai_name,
                    "message": full_response,
                    "timestamp": datetime.now().isoformat()
                })
            
            yield "data: [COMPLETE]\n\n"
            
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
    
    return StreamingResponse(generate(), media_type="text/event-stream")

# ==================== ëŒ€í™” íˆìŠ¤í† ë¦¬ ====================

@app.get("/api/history")
async def get_history():
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    return {
        "success": True,
        "history": chat_history,
        "count": len(chat_history)
    }

@app.delete("/api/history")
async def clear_history():
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
    global chat_history
    chat_history = []
    return {
        "success": True,
        "message": "ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤"
    }

# ==================== ë¬¸ì„œ ê´€ë¦¬ ====================

@app.get("/api/documents")
async def list_documents():
    """ì—…ë¡œë“œëœ ë¬¸ì„œ ëª©ë¡"""
    return await file_search_manager.list_documents()

@app.delete("/api/documents/{document_id:path}")
async def delete_document(document_id: str):
    """ë¬¸ì„œ ì‚­ì œ"""
    return await file_search_manager.delete_document(document_id)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
